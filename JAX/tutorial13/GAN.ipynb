{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 13 (JAX): Generative Adversarial Networks\n",
    "\n",
    "![Status](https://img.shields.io/static/v1.svg?label=Status&message=Finished&color=green)\n",
    "\n",
    "**Filled notebook:** \n",
    "[![View on Github](https://img.shields.io/static/v1.svg?logo=github&label=Repo&message=View%20On%20Github&color=lightgrey)](https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/JAX/tutorial13/GAN.ipynb)\n",
    "[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/JAX/tutorial13/GAN.ipynb)     \n",
    "**Pre-trained models:** \n",
    "[![View files on Github](https://img.shields.io/static/v1.svg?logo=github&label=Repo&message=View%20On%20Github&color=lightgrey)](https://github.com/phlippe/saved_models/tree/main/JAX/tutorial13)   \n",
    "**PyTorch version:**\n",
    "[![View on RTD](https://img.shields.io/static/v1.svg?logo=readthedocs&label=RTD&message=View%20On%20RTD&color=8CA1AF)](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial13/GAN.html)   \n",
    "**Author:** Phillip Lippe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Note:** This notebook is written in JAX+Flax. It is a 1-to-1 translation of the original notebook written in PyTorch+PyTorch Lightning with almost identical results. For an introduction to JAX, check out our [Tutorial 2 (JAX): Introduction to JAX+Flax](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/JAX/tutorial2/Introduction_to_JAX.html). Further, throughout the notebook, we comment on major differences to the PyTorch version and provide explanations for the major parts of the JAX code.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Speed comparison**: We will report a speed comparison between the PyTorch and JAX/Flax implementation here soon.\n",
    "    \n",
    "| Models                |   PyTorch   |     JAX     |\n",
    "|-----------------------|:-----------:|:-----------:|\n",
    "| Simple GAN            |  -min  -sec |  -min  -sec |\n",
    "| StyleGAN 2            |  -min  -sec |  -min  -sec |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Intro to GANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phillip/anaconda3/envs/dl2020/lib/python3.7/site-packages/chex/_src/pytypes.py:37: FutureWarning: jax.tree_structure is deprecated, and will be removed in a future release. Use jax.tree_util.tree_structure instead.\n",
      "  PyTreeDef = type(jax.tree_structure(None))\n",
      "WARNING:absl:GlobalAsyncCheckpointManager is not imported correctly. Checkpointing of GlobalDeviceArrays will not be available.To use the feature, install tensorstore.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: gpu:0\n"
     ]
    }
   ],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from typing import Any\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "plt.set_cmap('cividis')\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgb\n",
    "import seaborn as sns\n",
    "\n",
    "## tqdm for progress bars\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "## To run JAX on TPU in Google Colab, uncomment the two lines below\n",
    "# import jax.tools.colab_tpu\n",
    "# jax.tools.colab_tpu.setup_tpu()\n",
    "\n",
    "## JAX\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from jax.tree_util import tree_map\n",
    "\n",
    "## Flax (NN in JAX)\n",
    "try:\n",
    "    import flax\n",
    "except ModuleNotFoundError: # Install flax if missing\n",
    "    !pip install --quiet flax\n",
    "    import flax\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state, checkpoints\n",
    "\n",
    "## Optax (Optimizers in JAX)\n",
    "try:\n",
    "    import optax\n",
    "except ModuleNotFoundError: # Install optax if missing\n",
    "    !pip install --quiet optax\n",
    "    import optax\n",
    "\n",
    "## PyTorch Data Loading\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# Torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "# Path to the folder where the datasets are/should be downloaded (e.g. MNIST)\n",
    "DATASET_PATH = \"../../data\"\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = \"../../saved_models/tutorial13_jax\"\n",
    "\n",
    "print(\"Device:\", jax.devices()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "# Github URL where saved models are stored for this tutorial\n",
    "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/JAX/tutorial13/\"\n",
    "# Files to download\n",
    "pretrained_files = []\n",
    "# Create checkpoint path if it doesn't exist yet\n",
    "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
    "\n",
    "# For each file, check whether it already exists. If not, try downloading it.\n",
    "for file_name in pretrained_files:\n",
    "    file_path = os.path.join(CHECKPOINT_PATH, file_name)\n",
    "    if not os.path.isfile(file_path):\n",
    "        file_url = base_url + file_name\n",
    "        print(f\"Downloading {file_url}...\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(file_url, file_path)\n",
    "        except HTTPError as e:\n",
    "            print(\"Something went wrong. Please try to download the file from the GDrive folder, or contact the author with the full output including the following error:\\n\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations applied on each image => bring them into a numpy array and normalize\n",
    "def image_to_numpy(img):\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    img = img / 255. * 2. - 1. # Bring between -1 and 1\n",
    "    img = img[..., None]  # Make image [28, 28, 1]\n",
    "    return img\n",
    "\n",
    "# We need to stack the batch elements\n",
    "def numpy_collate(batch):\n",
    "    if isinstance(batch[0], np.ndarray):\n",
    "        return np.stack(batch)\n",
    "    elif isinstance(batch[0], (tuple, list)):\n",
    "        transposed = zip(*batch)\n",
    "        return [numpy_collate(samples) for samples in transposed]\n",
    "    else:\n",
    "        return np.array(batch)\n",
    "\n",
    "# Loading the training dataset. We need to split it into a training and validation part\n",
    "train_dataset = MNIST(root=DATASET_PATH, train=True,\n",
    "                      transform=image_to_numpy, download=True)\n",
    "train_set, val_set = torch.utils.data.random_split(train_dataset, [50000, 10000],\n",
    "                                                   generator=torch.Generator().manual_seed(42))\n",
    "# Loading the test set\n",
    "test_set = MNIST(root=DATASET_PATH, train=False,\n",
    "                 transform=image_to_numpy, download=True)\n",
    "\n",
    "# We define a set of data loaders that we can use for various purposes\n",
    "train_loader = data.DataLoader(train_set,\n",
    "                               batch_size=32,\n",
    "                               shuffle=True,\n",
    "                               drop_last=True,\n",
    "                               collate_fn=numpy_collate,\n",
    "                               num_workers=0)\n",
    "val_loader = data.DataLoader(val_set, batch_size=32, shuffle=False,\n",
    "                             drop_last=False, num_workers=0, collate_fn=numpy_collate)\n",
    "test_loader = data.DataLoader(test_set, batch_size=32, shuffle=False,\n",
    "                              drop_last=False, num_workers=0, collate_fn=numpy_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/pdf": "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\n",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"177.48pt\" version=\"1.1\" viewBox=\"0 0 335.299355 177.48\" width=\"335.299355pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2022-10-26T12:38:11.429828</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 177.48 \n",
       "L 335.299355 177.48 \n",
       "L 335.299355 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g clip-path=\"url(#p3ac9cd3f79)\">\n",
       "    <image height=\"164\" id=\"image6ac799c054\" transform=\"scale(1 -1)translate(0 -164)\" width=\"321\" x=\"7.2\" xlink:href=\"data:image/png;base64,\n",
       "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\" y=\"-6.28\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p3ac9cd3f79\">\n",
       "   <rect height=\"163.08\" width=\"320.899355\" x=\"7.2\" y=\"7.2\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 432x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imgs_to_grid(imgs, nrow=-1, ncol=-1):\n",
    "    imgs = jax.device_get(imgs)\n",
    "    if isinstance(imgs, (list, tuple)):\n",
    "        imgs = np.stack(imgs, axis=0)\n",
    "    num_imgs = imgs.shape[0]\n",
    "    if nrow == -1 or ncol == -1:\n",
    "        if num_imgs < 4 or num_imgs % 4 == 0:\n",
    "            nrow = min(num_imgs, 4)\n",
    "            ncol = int(math.ceil(num_imgs/nrow))\n",
    "        else:\n",
    "            nrow = num_imgs\n",
    "            ncol = 1\n",
    "    imgs = np.pad(imgs, pad_width=[(0,0), (1,1), (1,1), (0,0)], constant_values=0)\n",
    "    imgs = np.reshape(imgs, (nrow, ncol, *imgs.shape[1:]))\n",
    "    imgs = np.transpose(imgs, (1, 2, 0, 3, 4))\n",
    "    imgs = np.reshape(imgs, (imgs.shape[0]*imgs.shape[1], imgs.shape[2]*imgs.shape[3], -1))\n",
    "    imgs = np.pad(imgs, pad_width=[(1,1), (1,1), (0,0)], constant_values=0)\n",
    "    imgs = (imgs + 1.) / 2.\n",
    "    imgs = np.squeeze(imgs, axis=-1)\n",
    "    return imgs, (nrow, ncol)\n",
    "\n",
    "def show_imgs(imgs, show=True):\n",
    "    imgs, (nrow, ncol) = imgs_to_grid(imgs)\n",
    "    plt.figure(figsize=(1.5*nrow, 1.5*ncol))\n",
    "    plt.imshow(imgs, interpolation='nearest', cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "show_imgs([train_set[i][0] for i in range(8)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple GAN on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTGenerator(nn.Module):\n",
    "    c_hid : int\n",
    "    latent_dim : int\n",
    "    c_out : int = 1\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, z, **kwargs):\n",
    "        if len(z.shape) == 2:\n",
    "            z = z[:,None,None,:]\n",
    "        conv = partial(nn.ConvTranspose, \n",
    "                       kernel_size=(4, 4), \n",
    "                       kernel_init=nn.initializers.he_normal())\n",
    "        z = conv(features=4*self.c_hid, strides=(1, 1), padding='VALID')(z) # 4x4\n",
    "        z = nn.leaky_relu(z, 0.2) * np.sqrt(2)\n",
    "        z = conv(features=2*self.c_hid, kernel_size=(4, 4), strides=(2, 2))(z) # 8x8\n",
    "        z = nn.leaky_relu(z, 0.2) * np.sqrt(2)\n",
    "        z = conv(features=self.c_hid, kernel_size=(4, 4), strides=(2, 2))(z) # 16x16\n",
    "        z = nn.leaky_relu(z, 0.2) * np.sqrt(2)\n",
    "        z = conv(features=self.c_hid, kernel_size=(4, 4), strides=(2, 2), padding=0)(z) # 28x28\n",
    "        z = nn.leaky_relu(z, 0.2) * np.sqrt(2)\n",
    "        z = conv(features=self.c_out, kernel_size=(1, 1))(z)\n",
    "        z = nn.tanh(z)\n",
    "        return z\n",
    "    \n",
    "    def generate(self, rng, batch_size):\n",
    "        z = random.normal(rng, (batch_size, self.latent_dim))\n",
    "        return self.__call__(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 28, 28, 1)\n",
      "0.13224345\n",
      "(4, 4, 64, 128)\n"
     ]
    }
   ],
   "source": [
    "rng = random.PRNGKey(0)\n",
    "inp = random.normal(rng, (256, 64))\n",
    "model = MNISTGenerator(c_hid=32, c_out=1, latent_dim=inp.shape[-1])\n",
    "params = model.init(random.PRNGKey(1), inp)\n",
    "out = model.apply(params, inp)\n",
    "print(out.shape)\n",
    "print(out.std(axis=0).mean())\n",
    "_ = model.bind(params).generate(rng, 1)\n",
    "print(params['params']['ConvTranspose_0']['kernel'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDiscriminator(nn.Module):\n",
    "    c_hid : int\n",
    "    c_in : int = 1\n",
    "        \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Conv(features=self.c_hid, kernel_size=(3, 3), strides=2, padding=3)(x)  # 28x28 => 16x16\n",
    "        x = nn.leaky_relu(x, 0.2)\n",
    "        x = nn.Conv(features=2*self.c_hid, kernel_size=(3, 3), strides=2)(x)  # 16x16 => 8x8\n",
    "        x = nn.leaky_relu(x, 0.2)\n",
    "        x = nn.Conv(features=4*self.c_hid, kernel_size=(3, 3), strides=2)(x)  # 8x8 => 4x4\n",
    "        x = nn.leaky_relu(x, 0.2)\n",
    "        x = nn.Conv(features=1, kernel_size=(4, 4), padding=0)(x)\n",
    "        x = jnp.squeeze(x, axis=(1,2,3))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,)\n"
     ]
    }
   ],
   "source": [
    "rng = random.PRNGKey(0)\n",
    "inp = random.normal(rng, (64, 28, 28, 1))\n",
    "model = MNISTDiscriminator(c_hid=32, c_in=1)\n",
    "params = model.init(rng, inp)\n",
    "out = model.apply(params, inp)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(generator, discriminator_bd, batch_size, rng, params_gen):\n",
    "    model_rng, z_rng = random.split(rng)\n",
    "    z = random.normal(z_rng, (batch_size, generator.latent_dim))\n",
    "    x_fake = generator.apply(params_gen, z, rng=model_rng)\n",
    "    D_fake = discriminator_bd(x_fake)\n",
    "    loss = -nn.log_sigmoid(D_fake).mean()\n",
    "    return loss, (x_fake, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(discriminator, generator_bd, x_real, rng, params_dis):\n",
    "    x_fake = generator_bd.generate(rng, batch_size=x_real.shape[0])\n",
    "    x = jnp.concatenate([x_real, x_fake], axis=0)\n",
    "    D_out = discriminator.apply(params_dis, x)\n",
    "    D_real, D_fake = jnp.split(D_out, 2, axis=0)\n",
    "    loss_real = -nn.log_sigmoid(D_real).mean()\n",
    "    loss_fake = -nn.log_sigmoid(-D_fake).mean()\n",
    "    acc = ((D_real > 0).mean() + (D_fake < 0).mean()) / 2.\n",
    "    loss = (loss_real + loss_fake) / 2.\n",
    "    return loss, (acc, loss_real, loss_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateCallback:\n",
    "    \n",
    "    def __init__(self, generator, every_n_epochs=1):\n",
    "        self.every_n_epochs = every_n_epochs\n",
    "        self.gen_fn = jax.jit(lambda p: generator.bind(p).generate(random.PRNGKey(0), batch_size=64))\n",
    "        \n",
    "    def log_generations(self, params_gen, logger, epoch):\n",
    "        if epoch % self.every_n_epochs == 0:\n",
    "            gen_imgs = self.gen_fn(params_gen)\n",
    "            gen_imgs, _ = imgs_to_grid(gen_imgs, nrow=8, ncol=8)\n",
    "            logger.add_image('Generations', gen_imgs[None], global_step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainState(train_state.TrainState):\n",
    "    rng : Any = None\n",
    "    ema_params : Any = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainerModule:\n",
    "\n",
    "    def __init__(self, model_name, lr_gen=1e-4, lr_dis=2e-4, ema_factor=0.9, seed=42, **model_kwargs):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.lr_gen = lr_gen\n",
    "        self.lr_dis = lr_dis\n",
    "        self.ema_factor = ema_factor\n",
    "        self.seed = seed\n",
    "        # Create empty model. Note: no parameters yet\n",
    "        self.create_models(**model_kwargs)\n",
    "        # Prepare logging\n",
    "        self.log_dir = os.path.join(CHECKPOINT_PATH, self.model_name)\n",
    "        self.generate_callback = GenerateCallback(self.generator, every_n_epochs=1)\n",
    "        self.logger = SummaryWriter(log_dir=self.log_dir)\n",
    "        # Create jitted training and eval functions\n",
    "        self.create_functions()\n",
    "        # Initialize model\n",
    "        self.init_model()\n",
    "        \n",
    "    def create_models(self, c_hid, latent_dim, **kwargs):\n",
    "        self.discriminator = MNISTDiscriminator(c_hid=c_hid)\n",
    "        self.generator = MNISTGenerator(c_hid=c_hid, latent_dim=latent_dim)\n",
    "\n",
    "    def create_functions(self):\n",
    "        # Training function\n",
    "        def train_step(state_gen, state_dis, batch):\n",
    "            x_real, _ = batch\n",
    "            rng_gen, step_gen_rng = random.split(state_gen.rng)\n",
    "            rng_dis, step_dis_rng = random.split(state_dis.rng)\n",
    "            # Generator gradients\n",
    "            loss_fn_gen = lambda p: generator_loss(self.generator,\n",
    "                                                   self.discriminator.bind(state_dis.params),\n",
    "                                                   batch_size=x_real.shape[0],\n",
    "                                                   rng=step_gen_rng,\n",
    "                                                   params_gen=p)\n",
    "            (G_loss, _), grads_gen = jax.value_and_grad(loss_fn_gen, \n",
    "                                                        has_aux=True)(state_gen.params)\n",
    "            # Discriminator gradients\n",
    "            loss_fn_dis = lambda p: discriminator_loss(self.discriminator,\n",
    "                                                       self.generator.bind(state_gen.ema_params),\n",
    "                                                       x_real,\n",
    "                                                       rng=step_dis_rng,\n",
    "                                                       params_dis=p)\n",
    "            D_out, grads_dis = jax.value_and_grad(loss_fn_dis,\n",
    "                                                  has_aux=True)(state_dis.params)\n",
    "            D_loss, (D_acc, D_loss_real, D_loss_fake) = D_out\n",
    "            # Params updates\n",
    "            update_ema = lambda state: tree_map(lambda e, p: e * self.ema_factor + p * (1 - self.ema_factor), \n",
    "                                                state.ema_params, \n",
    "                                                state.params)\n",
    "            state_gen = state_gen.apply_gradients(grads=grads_gen, rng=rng_gen, ema_params=update_ema(state_gen))\n",
    "            state_dis = state_dis.apply_gradients(grads=grads_dis, rng=rng_dis, ema_params=update_ema(state_dis))\n",
    "            # Metrics\n",
    "            metrics = {'G_loss': G_loss, 'D_loss': D_loss, 'D_acc': D_acc,\n",
    "                       'D_loss_real': D_loss_real, 'D_loss_fake': D_loss_fake}\n",
    "            return state_gen, state_dis, metrics\n",
    "        self.train_step = jax.jit(train_step)\n",
    "\n",
    "    def init_model(self):\n",
    "        # Initialize model\n",
    "        rng = jax.random.PRNGKey(self.seed)\n",
    "        rng_gen, rng_dis, z_rng, init_gen_rng, for_gen_rng, init_dis_rng = jax.random.split(rng, 6)\n",
    "        z = random.normal(z_rng, (128, self.generator.latent_dim))\n",
    "        gen_out, params_gen = self.generator.init_with_output(init_gen_rng, z, rng=for_gen_rng)\n",
    "        params_dis = self.discriminator.init(init_dis_rng, gen_out)\n",
    "        # Initialize optimizer\n",
    "        optimizer_gen = optax.chain(\n",
    "            optax.clip(1.0),  # Clip gradients at 1\n",
    "            optax.adam(self.lr_gen, b1=0.5, b2=0.9)\n",
    "        )\n",
    "        optimizer_dis = optax.chain(\n",
    "            optax.clip(1.0),  # Clip gradients at 1\n",
    "            optax.adam(self.lr_dis, b1=0.5, b2=0.9)\n",
    "        )\n",
    "        # Initialize training state\n",
    "        self.state_gen = TrainState.create(apply_fn=self.generator.apply, \n",
    "                                           params=params_gen,\n",
    "                                           ema_params=params_gen,\n",
    "                                           tx=optimizer_gen,\n",
    "                                           rng=rng_gen)\n",
    "        self.state_dis = TrainState.create(apply_fn=self.discriminator.apply,\n",
    "                                           params=params_dis,\n",
    "                                           ema_params=params_dis,\n",
    "                                           tx=optimizer_dis,\n",
    "                                           rng=rng_dis)\n",
    "\n",
    "    def train_model(self, train_loader, val_loader, num_epochs=500):\n",
    "        # Train model for defined number of epochs\n",
    "        best_eval = 1e6\n",
    "        self.generate_callback.log_generations(self.state_gen.params, logger=self.logger, epoch=0)\n",
    "        for epoch_idx in tqdm(range(1, num_epochs+1)):\n",
    "            self.train_epoch(train_loader, epoch=epoch_idx)\n",
    "            self.generate_callback.log_generations(self.state_gen.params, logger=self.logger, epoch=epoch_idx)\n",
    "            if epoch_idx % 10 == 0:\n",
    "                self.save_model(step=epoch_idx)\n",
    "                self.logger.flush()\n",
    "\n",
    "    def train_epoch(self, train_loader, epoch):\n",
    "        # Train model for one epoch, and log avg loss\n",
    "        losses = defaultdict(list)\n",
    "        dataset_size = len(train_loader)\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            self.state_gen, self.state_dis, metrics = self.train_step(self.state_gen, self.state_dis, batch)\n",
    "            for key in metrics:\n",
    "                losses[key].append(metrics[key])\n",
    "                if (batch_idx + 1) % 50 == 0 or batch_idx + 1 == dataset_size:\n",
    "                    metric_np = np.stack(jax.device_get(losses.pop(key)))\n",
    "                    avg_metric = metric_np.mean()\n",
    "                    self.logger.add_scalar(f'train/{key}', avg_metric, global_step=epoch*dataset_size+batch_idx+1)\n",
    "\n",
    "    def save_model(self, step=0):\n",
    "        # Save current model at certain training iteration\n",
    "        params = {\n",
    "            'generator': self.state_gen.params,\n",
    "            'discriminator': self.state_dis.params\n",
    "        }\n",
    "        checkpoints.save_checkpoint(ckpt_dir=self.log_dir, target=params, \n",
    "                                    prefix=f'{self.model_name}_', step=step)\n",
    "\n",
    "    def load_model(self, pretrained=False):\n",
    "        # Load model. We use different checkpoint for pretrained models\n",
    "        if not pretrained:\n",
    "            params = checkpoints.restore_checkpoint(ckpt_dir=self.log_dir, target=None, prefix=f'{self.model_name}_')\n",
    "        else:\n",
    "            params = checkpoints.restore_checkpoint(ckpt_dir=os.path.join(CHECKPOINT_PATH, f'{self.model_name}.ckpt'), target=None)\n",
    "        self.state_gen = TrainState.create(apply_fn=self.state_gen.apply_fn, params=params['generator'], tx=self.state_gen.tx, rng=self.state_gen.rng)\n",
    "        self.state_dis = TrainState.create(apply_fn=self.state_dis.apply_fn, params=params['discriminator'], tx=self.state_dis.tx)\n",
    "\n",
    "    def checkpoint_exists(self):\n",
    "        # Check whether a pretrained model exist for this autoencoder\n",
    "        return os.path.isfile(os.path.join(CHECKPOINT_PATH, f'{self.model_name}.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(*args, trainer_class=TrainerModule, num_epochs=200, **kwargs):\n",
    "    # Create a trainer module with specified hyperparameters\n",
    "    trainer = trainer_class(*args, **kwargs)\n",
    "    if not trainer.checkpoint_exists():  # Skip training if pretrained model exists\n",
    "        trainer.train_model(train_loader, val_loader, num_epochs=num_epochs)\n",
    "        trainer.load_model()\n",
    "    else:\n",
    "        trainer.load_model(pretrained=True)\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = train_model(model_name='SimpleMNIST', \n",
    "#                       c_hid=16, latent_dim=64,\n",
    "#                       lr_gen=2e-4, lr_dis=2e-4, ema_factor=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StyleGAN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModulatedConv(nn.Module):\n",
    "    features : int\n",
    "    kernel_size : int = 3\n",
    "    demodulate : bool = True\n",
    "    eps : float = 1e-8\n",
    "        \n",
    "    @nn.compact\n",
    "    def __call__(self, x, s):\n",
    "        B, H, W, C = x.shape\n",
    "        # Create convolutional kernel\n",
    "        w = self.param('kernel', nn.initializers.lecun_normal(), # nn.initializers.normal(stddev=1.0),\n",
    "                       (self.kernel_size, self.kernel_size, C, self.features))\n",
    "        \n",
    "        # Weight kernel by modulation s\n",
    "        w = w[None] * s[:,None,None,:,None]\n",
    "        \n",
    "        # If true, we demodulate the kernel\n",
    "        if self.demodulate:\n",
    "            # Estimate 1 / l2 norm of w, eps for stabilization\n",
    "            d = jax.lax.rsqrt((w ** 2).sum(axis=(1, 2, 3), keepdims=True) + self.eps)\n",
    "            w = w * d\n",
    "        \n",
    "        # Apply convolution to input. Since each input has a different conv kernel,\n",
    "        # we define different 'groups' in the convolution which do not communicate\n",
    "        # For this, we flatten the batch and channel dimension\n",
    "        x = jnp.transpose(x, (1, 2, 0, 3))\n",
    "        x = x.reshape(1, H, W, B * C)\n",
    "        # Same we do with w\n",
    "        w = jnp.transpose(w, (1, 2, 3, 0, 4))\n",
    "        w = w.reshape(*w.shape[:3], B * self.features)\n",
    "        # Apply convolution with B groups\n",
    "        \n",
    "        ## TODO: CHECK OUT BATCH GROUP COUNT\n",
    "        x = jax.lax.conv_general_dilated(x, w, \n",
    "                                         window_strides=(1, 1),\n",
    "                                         padding='SAME',\n",
    "                                         dimension_numbers=nn.linear._conv_dimension_numbers(x.shape),\n",
    "                                         feature_group_count=B)\n",
    "        # print('W', w.std(), 'S', s.std())\n",
    "        # print('X', x.std())\n",
    "        # Reshape x to original form\n",
    "        x = x.reshape(H, W, B, self.features)\n",
    "        x = jnp.transpose(x, (2, 0, 1, 3))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 14, 14, 64)\n",
      "0.9518902\n",
      "[False False  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n"
     ]
    }
   ],
   "source": [
    "rng = random.PRNGKey(0)\n",
    "x = random.normal(rng, (128, 14, 14, 64))\n",
    "s = jnp.exp(random.normal(rng, (x.shape[0], x.shape[-1])))\n",
    "conv = ModulatedConv(features=64)\n",
    "params = conv.init(rng, x, s)\n",
    "out = conv.apply(params, x, s)\n",
    "print(out.shape)\n",
    "print(out.std())\n",
    "s = s.at[2,:].set(0.1)\n",
    "out2 = conv.apply(params, x, s)\n",
    "print((out != out2).any(axis=(1, 2, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorLayer(nn.Module):\n",
    "    features : int\n",
    "        \n",
    "    @nn.compact\n",
    "    def __call__(self, x, z, rng):\n",
    "        B, H, W, C = x.shape\n",
    "        # Map latent vector to style factors for this layer\n",
    "        style = nn.Dense(features=C,\n",
    "                         # kernel_init=nn.initializers.normal(stddev=1.0),\n",
    "                         bias_init=nn.initializers.ones)(z)\n",
    "        # Apply modulated conv on the input with style\n",
    "        x = ModulatedConv(self.features,\n",
    "                          kernel_size=3,\n",
    "                          demodulate=True)(x, style)\n",
    "        # print('X after mod', x.std())\n",
    "        # Add bias\n",
    "        bias = self.param('bias',\n",
    "                          nn.initializers.zeros,\n",
    "                          (1, 1, 1, self.features))\n",
    "        x = x + bias\n",
    "        # Apply random noise\n",
    "        noise = random.normal(rng, (B, H, W, 1))\n",
    "        noise_scaling = self.param('noise_scaling',\n",
    "                                   nn.initializers.zeros,\n",
    "                                   (1, 1, 1, self.features))\n",
    "        x = x + noise * noise_scaling\n",
    "        # Activation function\n",
    "        x = nn.leaky_relu(x, 0.2) * np.sqrt(2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Blur(nn.Module):\n",
    "    \n",
    "    def setup(self):\n",
    "        kernel = jnp.array([1, 2, 1])\n",
    "        kernel = kernel[None, :] * kernel[:, None]\n",
    "        kernel = kernel / kernel.sum()\n",
    "        kernel = kernel[:,:,None,None]\n",
    "        self.blur_kernel = kernel\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x = jnp.pad(x, ((0, 0), (1, 1), (1, 1), (0, 0)), 'edge')\n",
    "        x = jax.lax.conv_general_dilated(x, jnp.tile(self.blur_kernel, [1, 1, 1, x.shape[-1]]),\n",
    "                                         window_strides=(1, 1),\n",
    "                                         padding='VALID',\n",
    "                                         dimension_numbers=nn.linear._conv_dimension_numbers(x.shape),\n",
    "                                         feature_group_count=x.shape[-1])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-0.8627592  -0.05157972]\n",
      "   [-0.6586386  -0.26832023]\n",
      "   [-0.25579616 -0.42787594]]\n",
      "\n",
      "  [[-0.45864317 -0.26274782]\n",
      "   [-0.2933797  -0.5274103 ]\n",
      "   [-0.01100415 -0.69180477]]\n",
      "\n",
      "  [[-0.23446114 -0.5106406 ]\n",
      "   [-0.03690636 -0.7680731 ]\n",
      "   [ 0.22558092 -0.9408488 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.1911506  -0.0496189 ]\n",
      "   [ 0.17381474 -0.17504251]\n",
      "   [ 0.3115761  -0.3291268 ]]\n",
      "\n",
      "  [[ 0.09033134  0.12041623]\n",
      "   [ 0.36657652  0.03913856]\n",
      "   [ 0.7436601  -0.1003627 ]]\n",
      "\n",
      "  [[ 0.08979694  0.23039237]\n",
      "   [ 0.58170474  0.23877367]\n",
      "   [ 1.1616632   0.15215045]]]\n",
      "\n",
      "\n",
      " [[[ 0.5947954  -0.21732825]\n",
      "   [ 0.24929968 -0.28804177]\n",
      "   [-0.17831519 -0.3508661 ]]\n",
      "\n",
      "  [[ 0.30982223  0.288464  ]\n",
      "   [ 0.10423411  0.02131559]\n",
      "   [-0.21893662 -0.3163483 ]]\n",
      "\n",
      "  [[-0.07675925  0.853766  ]\n",
      "   [-0.15501294  0.41077104]\n",
      "   [-0.3694581  -0.16698697]]]\n",
      "\n",
      "\n",
      " [[[ 0.59077287 -0.47339386]\n",
      "   [ 0.4552713  -0.09232306]\n",
      "   [ 0.23564138  0.17344531]]\n",
      "\n",
      "  [[ 0.4805568  -0.6653577 ]\n",
      "   [ 0.5736375  -0.31587136]\n",
      "   [ 0.6075451  -0.07183921]]\n",
      "\n",
      "  [[ 0.27531233 -0.78349805]\n",
      "   [ 0.5719544  -0.50306094]\n",
      "   [ 0.856778   -0.3074584 ]]]]\n"
     ]
    }
   ],
   "source": [
    "inp = random.normal(random.PRNGKey(0), (4, 3, 3, 2))\n",
    "module = Blur()\n",
    "_ = module.init(random.PRNGKey(0), inp)\n",
    "out = module.apply({}, inp)\n",
    "out = module.apply({}, out)\n",
    "out.shape\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGBLayer(nn.Module):\n",
    "    c_out : int\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x, prev_rgb, z):\n",
    "        B, H, W, C = x.shape\n",
    "        \n",
    "        # print('X', x.std(), 'Z', z.std())\n",
    "        \n",
    "        style = nn.Dense(features=C,\n",
    "                         # kernel_init=nn.initializers.normal(stddev=1.0),\n",
    "                         bias_init=nn.initializers.ones)(z)\n",
    "        x = ModulatedConv(features=self.c_out, \n",
    "                          kernel_size=1,\n",
    "                          demodulate=False)(x, style)\n",
    "        \n",
    "        if prev_rgb is not None:\n",
    "            # In some implementation, the previous image is additionally blurred\n",
    "            prev_rgb = jax.image.resize(prev_rgb, (B, H, W, self.c_out), 'bilinear')\n",
    "            prev_rgb = Blur()(prev_rgb)\n",
    "            x = x + prev_rgb\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorBlock(nn.Module):\n",
    "    features : int\n",
    "    c_out : int = 3\n",
    "    num_layers : int = 2\n",
    "    upsample : bool = True\n",
    "        \n",
    "    @nn.compact\n",
    "    def __call__(self, x, prev_rgb, z, rng):\n",
    "        B, H, W, C = x.shape\n",
    "        if self.upsample:\n",
    "            x = jax.image.resize(x, (B, H*2, W*2, C), 'bilinear')\n",
    "        \n",
    "        for _ in range(self.num_layers):\n",
    "            rng, layer_rng = random.split(rng)\n",
    "            # print('X in (Gen layer)', x.std())\n",
    "            x = GeneratorLayer(features=self.features)(x, z, layer_rng)\n",
    "            # print('X out (Gen layer)', x.std())\n",
    "        \n",
    "        rgb = RGBLayer(c_out=self.c_out)(x, prev_rgb, z)\n",
    "        # print('RGB', rgb.std())\n",
    "        return x, rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleLinear(nn.Module):\n",
    "    features: int\n",
    "    lr_mul : float = 0.1\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        w = self.param('weight',\n",
    "                       nn.initializers.normal(stddev=1.0),\n",
    "                       (x.shape[-1], self.features))\n",
    "        b = self.param('bias',\n",
    "                       nn.initializers.zeros,\n",
    "                       (self.features,))\n",
    "        w = w * self.lr_mul\n",
    "        b = b * self.lr_mul\n",
    "        x = jnp.matmul(x, w) + b[None]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleNet(nn.Module):\n",
    "    latent_dim : int\n",
    "    num_layers : int\n",
    "    lr_mul : float = 0.1\n",
    "        \n",
    "    @nn.compact\n",
    "    def __call__(self, z):\n",
    "        # z = z / jnp.linalg.norm(z, axis=-1, keepdims=True)\n",
    "        z = z * jax.lax.rsqrt(jnp.mean(z ** 2, axis=1, keepdims=True) + 1e-8)\n",
    "        # print(z.std())\n",
    "        for idx in range(self.num_layers):\n",
    "            z = StyleLinear(features=self.latent_dim,\n",
    "                            lr_mul=self.lr_mul)(z)\n",
    "            z = nn.leaky_relu(z, 0.2) * np.sqrt(2)\n",
    "            # print(idx, z.std())\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleGANGenerator(nn.Module):\n",
    "    image_size : int\n",
    "    latent_dim : int = 256\n",
    "    base_c_hid : int = 16\n",
    "    max_c_hid : int = 256\n",
    "    c_out : int = 3\n",
    "    num_style_layers : int = 8\n",
    "    is_mnist : bool = False\n",
    "    mlp_lr_mul : float = 0.01\n",
    "    \n",
    "    def setup(self):\n",
    "        num_layers = int(np.log2(self.image_size) - 1)\n",
    "        c_hid = [min(self.max_c_hid, self.base_c_hid * (2 ** i)) for i in range(num_layers)][::-1]\n",
    "        self.init_const = self.param('init_const',\n",
    "                                     nn.initializers.normal(stddev=1.0),\n",
    "                                     (1, 4, 4, c_hid[0]))\n",
    "        self.init_conv = nn.Conv(features=c_hid[0], kernel_size=(3, 3), padding='SAME')\n",
    "        self.style_net = StyleNet(latent_dim=self.latent_dim,\n",
    "                                  num_layers=self.num_style_layers,\n",
    "                                  lr_mul=self.mlp_lr_mul)\n",
    "        self.blocks = [GeneratorBlock(features=c_hid[i],\n",
    "                                      upsample=(i > 0),\n",
    "                                      c_out=self.c_out)\n",
    "                       for i in range(num_layers)]\n",
    "        \n",
    "    def __call__(self, z, rng):\n",
    "        z = self.style_net(z)\n",
    "        # print('Z', z.std())\n",
    "        \n",
    "        x = self.init_conv(self.init_const)\n",
    "        # print('X init', x.std(), self.init_const.std())\n",
    "        x = jnp.repeat(x, z.shape[0], axis=0)\n",
    "        # print('X init', x.std())\n",
    "        rgb = None\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            rng, layer_rng = random.split(rng)\n",
    "            x, rgb = block(x, rgb, z, layer_rng)\n",
    "            \n",
    "        if self.is_mnist:\n",
    "            rgb = rgb[:,2:30,2:30]\n",
    "            \n",
    "        rgb = rgb / 3.0\n",
    "        # print('RGB', rgb.std())\n",
    "        # rgb = jnp.tanh(rgb)\n",
    "        \n",
    "        return rgb\n",
    "    \n",
    "    def generate(self, rng, batch_size):\n",
    "        z_rng, model_rng = random.split(rng)\n",
    "        z = random.normal(z_rng, (batch_size, self.latent_dim))\n",
    "        return self.__call__(z, model_rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorBlock(nn.Module):\n",
    "    features : int\n",
    "    downsample : bool = True\n",
    "        \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        # Skip connection with 1x1 convolution\n",
    "        res = nn.Conv(features=self.features,\n",
    "                      kernel_size=(1, 1),\n",
    "                      strides=(2 if self.downsample else 1))(x)\n",
    "        # Residual block\n",
    "        for _ in range(2):\n",
    "            x = nn.Conv(features=self.features, \n",
    "                        kernel_size=(3, 3))(x)\n",
    "            x = nn.leaky_relu(x, 0.2)\n",
    "        if self.downsample:\n",
    "            x = Blur()(x)\n",
    "            x = nn.Conv(features=self.features,\n",
    "                        kernel_size=(3, 3),\n",
    "                        strides=2)(x)\n",
    "        # Division by sqrt(2) to keep expected std constant\n",
    "        x = (x + res) / np.sqrt(2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinibatchStddev(nn.Module):\n",
    "    group_size : int = 8\n",
    "    eps : float = 1e-8\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        stats = x.reshape(self.group_size, -1, *x.shape[1:])\n",
    "        stats = stats - stats.mean(axis=0, keepdim=True)\n",
    "        stats = jnp.sqrt((stats ** 2).mean(axis=0) + self.eps)\n",
    "        stats = stats.mean(axis=(1, 2, 3), keepdim=True)\n",
    "        stats = stats.repeat(self.group_size, 1, 1, 1)\n",
    "        stats = stats.expand(-1, *x.shape[1:3], 1)\n",
    "        return jnp.concatenate([x, stats], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleGANDiscriminator(nn.Module):\n",
    "    image_size : int\n",
    "    base_c_hid : int = 16\n",
    "    max_c_hid : int = 256\n",
    "        \n",
    "    def setup(self):\n",
    "        num_layers = int(np.log2(self.image_size) - 1)\n",
    "        c_hid = [min(self.max_c_hid, self.base_c_hid * (2 ** i)) for i in range(num_layers)]\n",
    "        self.blocks = [DiscriminatorBlock(features=c_hid[i],\n",
    "                                          downsample=(i < num_layers-1))\n",
    "                       for i in range(num_layers)]\n",
    "        self.minibatch_stddev = MinibatchStddev()\n",
    "        self.final_conv = nn.Conv(features=c_hid[-1], kernel_size=(3, 3))\n",
    "        self.output_layer = nn.Dense(features=1)\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.final_conv(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.output_layer(x)\n",
    "        x = x.squeeze(axis=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r1_reg(discriminator, x_real, params_dis):\n",
    "    apply_dis = lambda img: discriminator.apply(params_dis, img).sum()\n",
    "    r1_grads = jax.grad(apply_dis)(x_real)\n",
    "    r1_penalty = (r1_grads ** 2).sum(axis=(1, 2, 3)).mean()\n",
    "    return r1_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleGANTrainerModule(TrainerModule):\n",
    "    \n",
    "    def __init__(self, *args, r1_weight=8.0, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.r1_weight = r1_weight\n",
    "    \n",
    "    def create_models(self, image_size, latent_dim, is_mnist, c_out, **kwargs):\n",
    "        self.discriminator = StyleGANDiscriminator(image_size=image_size)\n",
    "        self.generator = StyleGANGenerator(image_size=image_size, \n",
    "                                           latent_dim=latent_dim,\n",
    "                                           is_mnist=is_mnist,\n",
    "                                           num_style_layers=4,\n",
    "                                           mlp_lr_mul=1/np.sqrt(512),\n",
    "                                           c_out=c_out)\n",
    "    \n",
    "    def create_functions(self):\n",
    "        # Training function\n",
    "        def train_step(state_gen, state_dis, batch):\n",
    "            x_real, _ = batch\n",
    "            rng_gen, step_gen_rng = random.split(state_gen.rng)\n",
    "            rng_dis, step_dis_rng = random.split(state_dis.rng)\n",
    "            # Generator gradients\n",
    "            loss_fn_gen = lambda p: generator_loss(self.generator,\n",
    "                                                   self.discriminator.bind(state_dis.params),\n",
    "                                                   batch_size=x_real.shape[0],\n",
    "                                                   rng=step_gen_rng,\n",
    "                                                   params_gen=p)\n",
    "            (G_loss, _), grads_gen = jax.value_and_grad(loss_fn_gen, \n",
    "                                                        has_aux=True)(state_gen.params)\n",
    "            # Discriminator gradients\n",
    "            loss_fn_dis = lambda p: discriminator_loss(self.discriminator,\n",
    "                                                       self.generator.bind(state_gen.ema_params),\n",
    "                                                       x_real,\n",
    "                                                       rng=step_dis_rng,\n",
    "                                                       params_dis=p)\n",
    "            D_out, grads_dis = jax.value_and_grad(loss_fn_dis,\n",
    "                                                  has_aux=True)(state_dis.params)\n",
    "            D_loss, (D_acc, D_loss_real, D_loss_fake) = D_out\n",
    "            \n",
    "            # Discriminator regularization\n",
    "            reg_fn_dis = lambda p: r1_reg(self.discriminator,\n",
    "                                          x_real,\n",
    "                                          params_dis=p)\n",
    "            D_loss_reg, grads_reg_dis = jax.value_and_grad(reg_fn_dis,\n",
    "                                                           has_aux=False)(state_dis.params)\n",
    "            grads_dis = tree_map(lambda g, gr: g + gr * self.r1_weight, \n",
    "                                 grads_dis, \n",
    "                                 grads_reg_dis)\n",
    "            \n",
    "            # Params updates\n",
    "            update_ema = lambda state: tree_map(lambda e, p: e * self.ema_factor + p * (1 - self.ema_factor), \n",
    "                                                state.ema_params, \n",
    "                                                state.params)\n",
    "            state_gen = state_gen.apply_gradients(grads=grads_gen, rng=rng_gen, ema_params=update_ema(state_gen))\n",
    "            state_dis = state_dis.apply_gradients(grads=grads_dis, rng=rng_dis, ema_params=update_ema(state_dis))\n",
    "            # Metrics\n",
    "            metrics = {'G_loss': G_loss, 'D_loss': D_loss, 'D_acc': D_acc,\n",
    "                       'D_loss_real': D_loss_real, 'D_loss_fake': D_loss_fake,\n",
    "                       'D_loss_reg': D_loss_reg}\n",
    "            return state_gen, state_dis, metrics\n",
    "        self.train_step = jax.jit(train_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.044194173824159216"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/np.sqrt(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38f3fcd5c0eb4de7a75228825e7e7331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-166-e2b51a29a8a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                       \u001b[0mlr_dis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                       \u001b[0mema_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.995\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                       c_out=1)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-002698fcfb85>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(trainer_class, num_epochs, *args, **kwargs)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Skip training if pretrained model exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-0ad6534f6b0e>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, train_loader, val_loader, num_epochs)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_generations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_generations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-0ad6534f6b0e>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, train_loader, epoch)\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdataset_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                     \u001b[0mmetric_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m                     \u001b[0mavg_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'train/{key}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdataset_size\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl2020/lib/python3.7/site-packages/jax/_src/api.py\u001b[0m in \u001b[0;36mdevice_get\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2923\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtree_leaves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2924\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2925\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_to_host_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2926\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2927\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = train_model(trainer_class=StyleGANTrainerModule,\n",
    "                      model_name='StyleGAN',\n",
    "                      is_mnist=True,\n",
    "                      image_size=32,\n",
    "                      latent_dim=512,\n",
    "                      lr_gen=2e-4,\n",
    "                      lr_dis=2e-4,\n",
    "                      ema_factor=0.995,\n",
    "                      c_out=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
